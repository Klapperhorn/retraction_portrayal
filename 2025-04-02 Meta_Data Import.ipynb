{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43471ef5-730c-4433-b0d2-f9cb5b3ef095",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install openpyxl\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "def d(l):\n",
    "    pd.set_option('display.max_colwidth', l)\n",
    "\n",
    "d(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2703aab-2448-4017-9580-08423522dd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "science=pd.read_excel(\"2025-04-02 METADATA_ science-nature_V2.xlsx\",sheet_name=\"METADATA Science\")[[\"ID\",\"Date\",\"Type\",\"Doi\"]]\n",
    "nature=pd.read_excel(\"2025-04-02 METADATA_ science-nature_V2.xlsx\",sheet_name=\"METADATA Nature\")[[\"ID\",\"Date\",\"Type\",\"Doi\"]]\n",
    "\n",
    "df_old=pd.read_excel(\"Single item merged file.xlsx\", usecols=['ID_Paper','Type Recoded','Type','Date YYMMDD']) # File from Fred & Auste : Better data than in the other files (in these columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ac807e3-78a3-44c5-b4a0-ed9eeaf7ece6",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_retract=pd.read_json(\"2025-04-03 full data with GPT4o-mini_response.json\")\n",
    "GPT_retract[\"ID\"]=GPT_retract.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c03e97-0186-45cb-b1a8-e4462898d445",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88f02996-6cd7-4d45-b900-b169523c7b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Science17     Science17\n",
       "Science158    Scienc...\n",
       "Science446    Scienc...\n",
       "Science394    Scienc...\n",
       "Science397    Scienc...\n",
       "                ...    \n",
       "Nature1699    Nature...\n",
       "Nature1692    Nature...\n",
       "Nature1687    Nature...\n",
       "Nature1686    Nature...\n",
       "Nature573     Nature573\n",
       "Name: ID, Length: 838, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Does this make sense ??\n",
    "\n",
    "from ast import literal_eval\n",
    "\n",
    "column_name_duplicated=\"text duplicated\"\n",
    "\n",
    "# Create a \"duplicated\" column by checking for duplicates in the processed text\n",
    "\n",
    "GPT_retract[column_name_duplicated] = GPT_retract.filtered_texts.apply(lambda x: \"\".join(x)).str[:100].duplicated(keep=False)\n",
    "x=GPT_retract[GPT_retract[column_name_duplicated]]\n",
    "\n",
    "x[\"ID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c088161c-521c-4ce0-b91c-f319e05805da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0988c23-eb6f-45e7-9bed-4fbba1dd4859",
   "metadata": {},
   "outputs": [],
   "source": [
    "nature_relevance=pd.read_excel(\"Nature tally.xlsx\")\n",
    "nature_relevance.columns=nature_relevance.columns.str.replace(\"3.eliminated\",\"3. eliminated\")\n",
    "nature_relevance.value_counts()\n",
    "\n",
    "science_relevance=pd.read_excel(\"science tally.xlsx\",sheet_name=\"final tally\")\n",
    "science_relevance.columns=science_relevance.columns.str.replace(\"retrieved \",\"retrieved\").str.replace(\"3.eliminated\",\"3. eliminated\")\n",
    "science_relevance.value_counts()\n",
    "\n",
    "\n",
    "elimination_columns=['1. eliminated because no pdf doc',\n",
    "       '2. eliminated because no occurance of retract',\n",
    "       '3. eliminated because editorial retraction',\n",
    "       '4. eliminated because book reviews, etc.',\n",
    "       '5. eliminated because scanned with other relevant doc, duplicate or other technical issue',\n",
    "       '6. eliminated because context/meaning']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32d46b06-767c-4981-b245-5897d4cb09ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum:  Yes    1018\n",
      "dtype: int64\n",
      "\n",
      "\n",
      " 8. retained for analysis\n",
      "No     1018\n",
      "Yes     377\n",
      "Name: count, dtype: int64\n",
      "Sum:  Yes    1178\n",
      "dtype: int64\n",
      "\n",
      "\n",
      " 8. retained for analysis\n",
      "No     1178\n",
      "Yes     656\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "science_eliminated=science_relevance[elimination_columns].apply(lambda x: x.str.title().value_counts())\n",
    "print(\"Sum: \",science_eliminated.sum(axis=1))\n",
    "print(\"\\n\\n\",science_relevance[\"8. retained for analysis\"].str.title().str.replace(\"X\",\"No\").value_counts())\n",
    "\n",
    "\n",
    "nature_eliminated=nature_relevance[elimination_columns].apply(lambda x: x.str.title().value_counts())\n",
    "print(\"Sum: \",nature_eliminated.sum(axis=1))\n",
    "print(\"\\n\\n\",nature_relevance[\"8. retained for analysis\"].str.title().value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dae62460-d618-4597-9102-22b195624af9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1. eliminated because no pdf doc</th>\n",
       "      <td>385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2. eliminated because no occurance of retract</th>\n",
       "      <td>518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3. eliminated because editorial retraction</th>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4. eliminated because book reviews, etc.</th>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5. eliminated because scanned with other relevant doc, duplicate or other technical issue</th>\n",
       "      <td>226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6. eliminated because context/meaning</th>\n",
       "      <td>806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            True\n",
       "1. elim...   385\n",
       "2. elim...   518\n",
       "3. elim...    61\n",
       "4. elim...   200\n",
       "5. elim...   226\n",
       "6. elim...   806"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all files\n",
    "\n",
    "df_relevance=pd.concat([science_relevance,nature_relevance])\n",
    "\n",
    "#add GPT_retract\n",
    "df_relevance=pd.merge(df_relevance,GPT_retract,left_on=\"ID\",right_on=\"ID\",how=\"outer\")\n",
    "\n",
    "df_relevance.iloc[:,3:]=df_relevance.iloc[:,3:].replace({'yes': True, 'Yes': True,\"YES\":True})\n",
    "#df_relevance[\"2. eliminated because no occurance of retract\"]\n",
    "\n",
    "df_relevance[elimination_columns].apply(lambda x: x.value_counts()).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d94add97-c059-4d2c-b44f-995a07a7735b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xb/hcrlz1px0q5byjc3wrssw2lm0000gn/T/ipykernel_8233/3472833730.py:4: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  x[elimination_columns].apply(lambda x: x.value_counts()).T\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1. eliminated because no pdf doc</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2. eliminated because no occurance of retract</th>\n",
       "      <td>111.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3. eliminated because editorial retraction</th>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4. eliminated because book reviews, etc.</th>\n",
       "      <td>198.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5. eliminated because scanned with other relevant doc, duplicate or other technical issue</th>\n",
       "      <td>226.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6. eliminated because context/meaning</th>\n",
       "      <td>806.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             True\n",
       "1. elim...    NaN\n",
       "2. elim...  111.0\n",
       "3. elim...   60.0\n",
       "4. elim...  198.0\n",
       "5. elim...  226.0\n",
       "6. elim...  806.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_relevance[\"retraction_revision\"]=(df_relevance[\"2. eliminated because no occurance of retract\"]==True) & (df_relevance[\"has_retraction\"]==True)\n",
    "\n",
    "x=df_relevance.dropna(subset=\"has_retraction\")\n",
    "x[elimination_columns].apply(lambda x: x.value_counts()).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40e52cb0-9cdc-41f1-add6-91d3e040f31e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       True\n",
       "1       True\n",
       "2       True\n",
       "3       True\n",
       "4        NaN\n",
       "        ... \n",
       "3224     NaN\n",
       "3225     NaN\n",
       "3226    True\n",
       "3227    True\n",
       "3228     NaN\n",
       "Name: has_retraction, Length: 3229, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_relevance[\"PDF retrieved\"]=df_relevance[\"PDF retrieved\"].replace(\"Yes but no OCR\",True)\n",
    "df_relevance.loc[df_relevance[\"PDF retrieved\"]!=True,\"PDF retrieved\"]=False\n",
    "df_relevance[\"PDF retrieved\"].value_counts()\n",
    "df_relevance[\"has_retraction\"].replace(1,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14b1a664-59bc-449a-af89-5c62fd133162",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.concat([science,nature])\n",
    "df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "from datetime import datetime\n",
    "df['Year']=df['Date'].apply(lambda x: x.year if isinstance(x,datetime) else x)\n",
    "df[\"journal\"]=df.ID.str.replace(r'\\d+', '', regex=True)\n",
    "\n",
    "# Recode the 'Type' column\n",
    "df['Type Recoded'] = df['Type'].replace({\n",
    "    'Perspectives and commentary': 'Contribution',\n",
    "    'Comments & Opinion': 'Contribution',\n",
    "    'Books & Arts': 'Book Reviews',\n",
    "    'News': 'Contribution',\n",
    "    'Correspondence': 'Journalism',\n",
    "    'Editorial': 'Journalism',\n",
    "    'other': 'Journalism',\n",
    "    'News & Views': 'Journalism',\n",
    "    'Special Features': 'Other',\n",
    "    'Not comment/opinion': 'Other',\n",
    "    'Meeting report': 'Other',\n",
    "    'Research Highlights': 'Other',\n",
    "    None: 'Other'\n",
    "})\n",
    "\n",
    "\n",
    "df_old['Date'] = pd.to_datetime(df_old['Date YYMMDD'], errors='coerce')\n",
    "df.dropna(subset=\"ID\",inplace=True)\n",
    "df=pd.merge(df,df_old,right_on=\"ID_Paper\",left_on=\"ID\",how=\"outer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "92ad82a7-8e82-48ee-a899-aa9cd6c32b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some metadata was recoded: \n",
    "\n",
    "#See\n",
    "#df[df[\"Date_x\"]!=df[\"Date_y\"]][[\"ID\",\"Date_x\",\"Date_y\"]].dropna()\n",
    "#df[df[\"Type_x\"]!=df[\"Type_y\"]][[\"ID\",\"Type_x\",\"Type_y\"]].dropna()\n",
    "\n",
    "\n",
    "# Action: I take the recoded ones!\n",
    "df[df[\"Type_x\"]!=df[\"Type_y\"]][[\"ID\",\"Type_x\",\"Type_y\"]].dropna()\n",
    "\n",
    "# Update Type_x only where Type_y has a value\n",
    "df[\"Type_x\"] = df[\"Type_x\"].where(df[\"Type_y\"].isna(), df[\"Type_y\"])\n",
    "df[\"Type Recoded_x\"] = df[\"Type Recoded_x\"].where(df[\"Type Recoded_y\"].isna(), df[\"Type Recoded_y\"])\n",
    "df[\"Date_x\"] = df[\"Date_x\"].where(df[\"Date_y\"].isna(), df[\"Date_y\"])\n",
    "\n",
    "df[\"confirmed_2024\"]=df.ID_Paper.isna()==False\n",
    "df.drop(columns=[\"Type_y\",\"Date_y\",'Type Recoded_y','Date YYMMDD',\"ID_Paper\"],inplace=True)\n",
    "df.columns = df.columns.str.replace('_x', '', regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "396531b5-6732-4843-b795-d137a76d0cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Year\"]=df[\"Date\"].dt.year\n",
    "df[\"7. eliminated because before 1960\"]=df[\"Date\"]<pd.to_datetime(\"01-01-1960\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46268478-37da-4dd8-abf1-59f822c42aa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e477594b-6c9b-4172-97e2-edfd23209d30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3231, 45)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final=pd.merge(df,df_relevance,on=[\"Doi\",\"ID\"],suffixes=[None,\"_y\"])\n",
    "\n",
    "\n",
    "## Manually add two more articles: Nature507b and Nature454b\n",
    "\n",
    "#--> These articles were missing in the initial meta-data overview and only later found as seperate articles within a PDF.\n",
    "#How do I add them? \n",
    "#- I increase the overall number of articles and the final number of articles by 2 and take these +2 through all other steps.\n",
    "#- I split the text in the textfile to make it two different articles.\n",
    "\n",
    "\n",
    "df_final.index=df_final.ID\n",
    "df_final.loc['Nature507b',:]=df_final.loc['Nature507',:]\n",
    "df_final.loc['Nature454b',:]=df_final.loc['Nature454',:]\n",
    "df_final.ID=df_final.index\n",
    "\n",
    "df_final['1. eliminated because no pdf']=df_final['PDF retrieved']==False\n",
    "df_final['2. eliminated because corrupt file or no keyword']=df_final[\"text\"].isna()\n",
    "\n",
    "\n",
    "df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a41542b0-b257-4b6c-8bea-5f3a557ca087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'Date', 'Type', 'Doi', 'Year', 'journal', 'Type Recoded',\n",
       "       'confirmed_2024', '7. eliminated because before 1960', 'Title',\n",
       "       'PDF retrieved', 'If no, why?', 'Appears in first context document?',\n",
       "       'If no, why?.1', 'Appears in second context document?',\n",
       "       '1. eliminated because no pdf doc',\n",
       "       '2. eliminated because no occurance of retract',\n",
       "       '3. eliminated because editorial retraction',\n",
       "       '4. eliminated because book reviews, etc.',\n",
       "       '5. eliminated because scanned with other relevant doc, duplicate or other technical issue',\n",
       "       '6. eliminated because context/meaning', '7. eliminated because….',\n",
       "       '8. retained for analysis', 'path', 'folder', 'journal_y', 'texts',\n",
       "       'labels', 'retraction_counts', 'has_retraction', 'retract_tokens',\n",
       "       'has_retraction_label', 'filtered_texts', 'neighboring_texts',\n",
       "       'texts_until_section_header', 'text', 'relevant', 'retraction_context',\n",
       "       'retraction_explanation', 'category', 'explanation', 'text duplicated',\n",
       "       'retraction_revision', '1. eliminated because no pdf',\n",
       "       '2. eliminated because corrupt file or no keyword'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "a79f3004-addf-4b77-a28e-0d2388e6d753",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "98a92649-9f6f-42b9-84e6-30dd1e883225",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_check=['1. eliminated because no pdf',\n",
    "                  '2. eliminated because corrupt file or no keyword',\n",
    "                  '3. eliminated because editorial retraction',\n",
    "       '4. eliminated because book reviews, etc.',\n",
    "       '5. eliminated because scanned with other relevant doc, duplicate or other technical issue',\n",
    "       '6. eliminated because context/meaning', \"7. eliminated because before 1960\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e5a0bfc1-6800-4e8f-9972-bbc56bff0e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before manual check of new files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xb/hcrlz1px0q5byjc3wrssw2lm0000gn/T/ipykernel_8233/826376612.py:13: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_final[\"8. retained for analysis\"]=df_final[\"8. retained for analysis\"].replace(\"No\",False).replace(\"no\",False).replace(\"x\",False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9. retained for analysis (revised)\n",
       "False    2166\n",
       "True     1065\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove text duplicates\n",
    "#df_final[\"9. retained for analysis (revised)\"]=(df_final[\"has_retraction\"]==True) & (~df_final[\"3-6 eliminated\"]==True) & (~df_final[column_name_duplicated].dropna()==True)\n",
    "\n",
    "# keep text duplicates\n",
    "df_final[\"PDF retrieved\"]=df_final[\"PDF retrieved\"].apply(lambda x: True if x==\"Yes but no OCR\" else x)\n",
    "\n",
    "\n",
    "df_final['1-7 eliminated'] = df_final[columns_to_check].apply(lambda row: row.any(), axis=1)\n",
    "\n",
    "\n",
    "df_final[\"9. retained for analysis (revised)\"]=(df_final[\"has_retraction\"]==True) & (~df_final[\"1-7 eliminated\"]==True)\n",
    "df_final[\"8. retained for analysis\"]=df_final[\"8. retained for analysis\"].replace({'yes': True, 'Yes': True, 'YES': True})\n",
    "df_final[\"8. retained for analysis\"]=df_final[\"8. retained for analysis\"].replace(\"No\",False).replace(\"no\",False).replace(\"x\",False)\n",
    "df_final.loc[df_final['PDF retrieved']!=True,'PDF retrieved']=False\n",
    "print(\"before manual check of new files\")\n",
    "df_final[\"9. retained for analysis (revised)\"].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4977c325-712f-41ad-98cb-3874d9e71630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually change the status of 3 articles which are duplications\n",
    "\n",
    "df_final.loc[['Science231',\"Science755\",\"Science200\"],'5. eliminated because scanned with other relevant doc, duplicate or other technical issue']=True\n",
    "df_final.loc[['Science231',\"Science755\",\"Science200\"],'8. retained for analysis']=False\n",
    "df_final.loc[['Science231',\"Science755\",\"Science200\"],'relevant']=False\n",
    "df_final.loc[['Science231',\"Science755\",\"Science200\"],\"9. retained for analysis (revised)\"]=False\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5dafeb21-88a1-4794-b00f-ccd5040cd607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9. retained for analysis (revised)\n",
       "False    2215\n",
       "True     1016\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Manually annotate new files\n",
    "\n",
    "# Compare the data lists and create a file with new files (from re-doing OCR & searching \"retraction\"\n",
    "df_final[\"NEW in the analysis\"]=(df_final[\"8. retained for analysis\"]==False) & (df_final[\"9. retained for analysis (revised)\"]==True) & (df_final[\"7. eliminated because before 1960\"]==False)\n",
    "df_final[\"REMOVED from the analysis\"]=(df_final[\"8. retained for analysis\"]==True) & (df_final[\"9. retained for analysis (revised)\"]==False) & (df_final[\"7. eliminated because before 1960\"]==False)\n",
    "df_final[df_final[\"NEW in the analysis\"]].to_excel(\"2025-04-25 new articles for manual annotation of retraction context.xlsx\")\n",
    "\n",
    "\n",
    "# Load the manually annotated articles\n",
    "include_manually_annotated = pd.read_excel(\"2025-04-26 new articles manually annotated.xlsx\")\n",
    "\n",
    "# Filter IDs based on the manual check\n",
    "new_exclude = include_manually_annotated[include_manually_annotated[\"Manual Check CONTEXT INCLUDE\"] != True][\"ID\"]\n",
    "new_include = include_manually_annotated[include_manually_annotated[\"Manual Check CONTEXT INCLUDE\"] == True][\"ID\"]\n",
    "\n",
    "# Update the df_final DataFrame\n",
    "df_final.loc[df_final['ID'].isin(new_exclude), '6. eliminated because context/meaning'] = True\n",
    "df_final.loc[df_final['ID'].isin(new_exclude), \"9. retained for analysis (revised)\"]=False\n",
    "\n",
    "\n",
    "df_final.loc[df_final['ID'].isin(new_include), ['2. eliminated because corrupt file or no keyword',\n",
    "                                                '3. eliminated because editorial retraction',\n",
    "                                                '4. eliminated because book reviews, etc.',\n",
    "                                                '5. eliminated because scanned with other relevant doc, duplicate or other technical issue',\n",
    "                                                '6. eliminated because context/meaning',\n",
    "                                                '3-7 eliminated']] = False\n",
    "df_final.loc[df_final['ID'].isin(new_include),\"9. retained for analysis (revised)\"]=True\n",
    "\n",
    "df_final[\"9. retained for analysis (revised)\"].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "028f81c8-7977-49a3-ad43-44d5734e178b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_final.to_excel(\"2025-06-07 all meta data.xlsx\")\n",
    "df_final.to_json(\"2025-06-07 all meta data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "201b44e6-449a-4c05-9112-85f88daf08e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID\n",
       "Nature10      True\n",
       "Nature1000    True\n",
       "Nature1005    True\n",
       "Nature1007    True\n",
       "Nature101     True\n",
       "              ... \n",
       "Science987    True\n",
       "Science992    True\n",
       "Science993    True\n",
       "Science994    True\n",
       "Science998    True\n",
       "Name: 6. eliminated because context/meaning, Length: 871, dtype: object"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop rows with missing values in the specified column and create a new DataFrame\n",
    "bad_context = df_final.dropna(subset=['6. eliminated because context/meaning'])\n",
    "# Select the relevant column from the new DataFrame\n",
    "bad_context['6. eliminated because context/meaning']\n",
    "#bad_context[[\"ID\",\"Doi\",\"Title\",\"Date\"]+elimination_columns+['7. eliminated because before 1960']].sort_values('7. eliminated because before 1960').to_excel(\"2025-04-03_context eliminations.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cd120b64-eff0-40f6-a62a-343f8f049e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2846\n",
      "2436\n",
      "2377\n",
      "2179\n",
      "1325\n",
      "23\n",
      "967 23 20\n",
      "891\n"
     ]
    }
   ],
   "source": [
    "withPDF=df_final[df_final[\"1. eliminated because no pdf\"]!=True]\n",
    "print(len(withPDF))\n",
    "\n",
    "withKeyword=withPDF[withPDF[\"2. eliminated because corrupt file or no keyword\"]!=True]\n",
    "print(len(withKeyword))\n",
    "\n",
    "NoEditR=withKeyword[withKeyword[\"3. eliminated because editorial retraction\"]!=True]\n",
    "print(len(NoEditR))\n",
    "\n",
    "NoBookR=NoEditR[NoEditR[\"4. eliminated because book reviews, etc.\"]!=True]\n",
    "print(len(NoBookR))\n",
    "\n",
    "CorrectContext=NoBookR[NoBookR[\"6. eliminated because context/meaning\"]!=True]\n",
    "print(len(CorrectContext))\n",
    "\n",
    "No_Duplicated=CorrectContext[CorrectContext[\"text duplicated\"]==False]\n",
    "\n",
    "No_DuplicatedProblem=CorrectContext[CorrectContext[\"text duplicated\"]==True]\n",
    "\n",
    "\n",
    "NoTechIssue=No_Duplicated[No_Duplicated[\"5. eliminated because scanned with other relevant doc, duplicate or other technical issue\"]!=True]\n",
    "\n",
    "No_DuplicatedTechIssue=No_Duplicated[No_Duplicated[\"5. eliminated because scanned with other relevant doc, duplicate or other technical issue\"]==True]\n",
    "print(len(No_DuplicatedTechIssue))\n",
    "\n",
    "\n",
    "\n",
    "After1960=NoTechIssue[NoTechIssue[\"7. eliminated because before 1960\"]!=True]\n",
    "No_DuplicatedTechIssueAfter1960=No_DuplicatedTechIssue[No_DuplicatedTechIssue[\"7. eliminated because before 1960\"]!=True]\n",
    "\n",
    "print(len(No_Duplicated),\n",
    "\n",
    "      len(No_DuplicatedTechIssue),\n",
    "      len(No_DuplicatedTechIssueAfter1960))\n",
    "\n",
    "print(len(After1960))\n",
    "\n",
    "strange=After1960[After1960[\"9. retained for analysis (revised)\"]!=True]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "bd2c7de8-7791-41ca-9de0-8a82a454057a",
   "metadata": {},
   "outputs": [],
   "source": [
    "No_DuplicatedTechIssueAfter1960.to_excel(\"2025-04-29 WhatTechIssue.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "971980be-c864-4878-9de0-7584512f38f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reorganize Column\n",
    "\n",
    "df_final2=df_final[['ID', 'Doi', 'journal' ,'Title', 'Date', 'Year', 'Type', 'Type Recoded',\n",
    "       'confirmed_2024',\n",
    "       'PDF retrieved','has_retraction',\n",
    "       '1. eliminated because no pdf',\n",
    "       '2. eliminated because corrupt file or no keyword',\n",
    "       '3. eliminated because editorial retraction',\n",
    "       '4. eliminated because book reviews, etc.',\n",
    "       '5. eliminated because scanned with other relevant doc, duplicate or other technical issue',\n",
    "       '6. eliminated because context/meaning', '7. eliminated because before 1960', '3-7 eliminated',\n",
    "       '8. retained for analysis',\"9. retained for analysis (revised)\"]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d321e190-8c1f-4df0-8ae2-a90f45e1088e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents: 3231\n",
      "Final remaining documents: 1016\n",
      "step_1: 1. eliminated because no pdf: 385, Remaining = 2846\n",
      "step_2: 2. eliminated because corrupt file or no keyword: 410, Remaining = 2436\n",
      "step_3: 3. eliminated because editorial retraction: 59, Remaining = 2377\n",
      "step_4: 4. eliminated because book reviews, etc.: 198, Remaining = 2179\n",
      "step_5: 5. eliminated because scanned with other relevant doc, duplicate or other technical issue: 228, Remaining = 1951\n",
      "step_6: 6. eliminated because context/meaning: 854, Remaining = 1097\n",
      "step_7: 7. eliminated because before 1960: 81, Remaining = 1016\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def filter_documents(df):\n",
    "    # Dictionary to store the results of each step\n",
    "    result = {}\n",
    "    \n",
    "    # Total number of documents\n",
    "    total_docs = len(df)\n",
    "    remaining_docs = df  # Start with the full DataFrame\n",
    "    \n",
    "    print(f\"Total documents: {total_docs}\")\n",
    "    \n",
    "    # Sequential filtering\n",
    "    for i in range(len(df.columns)):\n",
    "        # Get the current column (filter step)\n",
    "        current_filter = remaining_docs.iloc[:, i]  # Current filter column\n",
    "        \n",
    "        # Identify rows to eliminate and remaining rows\n",
    "        eliminated_docs = remaining_docs[current_filter == True]  # Rows to eliminate\n",
    "        remaining_docs = remaining_docs[current_filter != True]  # Remaining rows\n",
    "        \n",
    "        # Store the counts for reporting\n",
    "        result[f\"step_{i+1}: {df.columns[i]}\"] = {\n",
    "            \"eliminated_count\": len(eliminated_docs),\n",
    "            \"remaining_count\": len(remaining_docs)\n",
    "        }\n",
    "    \n",
    "    # Final remaining documents after all steps\n",
    "    final_docs = len(remaining_docs)\n",
    "    print(f\"Final remaining documents: {final_docs}\")\n",
    "    \n",
    "    # Print the results for each step\n",
    "    for step, values in result.items():\n",
    "        print(f\"{step}: {values['eliminated_count']}, Remaining = {values['remaining_count']}\")\n",
    "        \n",
    "    result[\"Total documents\"]=total_docs\n",
    "    return remaining_docs, result\n",
    "\n",
    "\n",
    "\n",
    "remaining_docs, result=filter_documents(df_final2.iloc[:,11:-3])\n",
    "\n",
    "result=pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "b8b8f36b-d307-41d7-8a4c-bbc2271b25d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(result).to_json(\"2025-06-07 filtering_results.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a1f2ee19-4da2-4026-a03f-be2c97df65ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "result=pd.read_json(\"2025-06-07 filtering_results.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "6517ee2f-0af3-4d83-9c13-a24ac6a0139b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Type</th>\n",
       "      <th>Doi</th>\n",
       "      <th>Year</th>\n",
       "      <th>journal</th>\n",
       "      <th>Type Recoded</th>\n",
       "      <th>confirmed_2024</th>\n",
       "      <th>7. eliminated because before 1960</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nature1</td>\n",
       "      <td>2023-06-22</td>\n",
       "      <td>News</td>\n",
       "      <td>10.103...</td>\n",
       "      <td>2023</td>\n",
       "      <td>Nature</td>\n",
       "      <td>Journa...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nature10</td>\n",
       "      <td>2023-04-27</td>\n",
       "      <td>Resear...</td>\n",
       "      <td>10.103...</td>\n",
       "      <td>2023</td>\n",
       "      <td>Nature</td>\n",
       "      <td>Other</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nature100</td>\n",
       "      <td>2021-06-09</td>\n",
       "      <td>Commen...</td>\n",
       "      <td>10.103...</td>\n",
       "      <td>2021</td>\n",
       "      <td>Nature</td>\n",
       "      <td>Journa...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nature...</td>\n",
       "      <td>1926-12-11</td>\n",
       "      <td>News</td>\n",
       "      <td>10.103...</td>\n",
       "      <td>1926</td>\n",
       "      <td>Nature</td>\n",
       "      <td>Contri...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nature...</td>\n",
       "      <td>2005-09-28</td>\n",
       "      <td>News</td>\n",
       "      <td>10.103...</td>\n",
       "      <td>2005</td>\n",
       "      <td>Nature</td>\n",
       "      <td>Contri...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3224</th>\n",
       "      <td>Scienc...</td>\n",
       "      <td>1963-09-27</td>\n",
       "      <td>Perspe...</td>\n",
       "      <td>10.112...</td>\n",
       "      <td>1963</td>\n",
       "      <td>Science</td>\n",
       "      <td>Contri...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3225</th>\n",
       "      <td>Scienc...</td>\n",
       "      <td>2001-09-21</td>\n",
       "      <td>Perspe...</td>\n",
       "      <td>10.112...</td>\n",
       "      <td>2001</td>\n",
       "      <td>Science</td>\n",
       "      <td>Contri...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3226</th>\n",
       "      <td>Scienc...</td>\n",
       "      <td>1918-03-01</td>\n",
       "      <td>Perspe...</td>\n",
       "      <td>10.112...</td>\n",
       "      <td>1918</td>\n",
       "      <td>Science</td>\n",
       "      <td>Contri...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3227</th>\n",
       "      <td>Scienc...</td>\n",
       "      <td>1918-03-01</td>\n",
       "      <td>Perspe...</td>\n",
       "      <td>10.112...</td>\n",
       "      <td>1918</td>\n",
       "      <td>Science</td>\n",
       "      <td>Contri...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3228</th>\n",
       "      <td>Scienc...</td>\n",
       "      <td>1888-07-12</td>\n",
       "      <td>Perspe...</td>\n",
       "      <td>10.112...</td>\n",
       "      <td>1888</td>\n",
       "      <td>Science</td>\n",
       "      <td>Contri...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3229 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID       Date       Type        Doi  Year  journal Type Recoded  \\\n",
       "0       Nature1 2023-06-22       News  10.103...  2023   Nature  Journa...     \n",
       "1      Nature10 2023-04-27  Resear...  10.103...  2023   Nature      Other     \n",
       "2     Nature100 2021-06-09  Commen...  10.103...  2021   Nature  Journa...     \n",
       "3     Nature... 1926-12-11       News  10.103...  1926   Nature  Contri...     \n",
       "4     Nature... 2005-09-28       News  10.103...  2005   Nature  Contri...     \n",
       "...         ...        ...        ...        ...   ...      ...        ...     \n",
       "3224  Scienc... 1963-09-27  Perspe...  10.112...  1963  Science  Contri...     \n",
       "3225  Scienc... 2001-09-21  Perspe...  10.112...  2001  Science  Contri...     \n",
       "3226  Scienc... 1918-03-01  Perspe...  10.112...  1918  Science  Contri...     \n",
       "3227  Scienc... 1918-03-01  Perspe...  10.112...  1918  Science  Contri...     \n",
       "3228  Scienc... 1888-07-12  Perspe...  10.112...  1888  Science  Contri...     \n",
       "\n",
       "      confirmed_2024  7. eliminated because before 1960  \n",
       "0          True           False                          \n",
       "1         False           False                          \n",
       "2          True           False                          \n",
       "3         False            True                          \n",
       "4         False           False                          \n",
       "...         ...             ...                          \n",
       "3224      False           False                          \n",
       "3225      False           False                          \n",
       "3226      False            True                          \n",
       "3227      False            True                          \n",
       "3228      False            True                          \n",
       "\n",
       "[3229 rows x 9 columns]"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "49713f69-9eba-497c-b582-6de64009a406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'Doi', 'journal', 'Title', 'Date', 'Year', 'Type', 'Type Recoded',\n",
       "       'confirmed_2024', 'PDF retrieved', 'has_retraction',\n",
       "       '1. eliminated because no pdf',\n",
       "       '2. eliminated because corrupt file or no keyword',\n",
       "       '3. eliminated because editorial retraction',\n",
       "       '4. eliminated because book reviews, etc.',\n",
       "       '5. eliminated because scanned with other relevant doc, duplicate or other technical issue',\n",
       "       '6. eliminated because context/meaning',\n",
       "       '7. eliminated because before 1960', '3-7 eliminated',\n",
       "       '8. retained for analysis', '9. retained for analysis (revised)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "db6c1ad7-7365-4fe2-ab08-9e924b4c8646",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final2[['ID', 'Doi','Year','1. eliminated because no pdf',\n",
    "       '2. eliminated because corrupt file or no keyword',\n",
    "       '3. eliminated because editorial retraction',\n",
    "       '4. eliminated because book reviews, etc.',\n",
    "       '5. eliminated because scanned with other relevant doc, duplicate or other technical issue',\n",
    "       '6. eliminated because context/meaning',\n",
    "       '7. eliminated because before 1960',\"9. retained for analysis (revised)\"]].to_excel(\"2025-06-25 Meta_data full.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "9a9a6572-5205-494a-8998-05772e79236d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Nature507     Dance ...\n",
       "Nature507b    GM stu...\n",
       "Nature454     Study ...\n",
       "Nature454b    types ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# manually split two texts: These PDFs have two seperate relevant texts on retraction in one file.\n",
    "\n",
    "df_txt=pd.read_json(\"2025-04-03 PDF Import complete.json\").dropna(subset=\"texts\") # This file contains all text. the later one only filtered text.\n",
    "\n",
    "ida1=df_txt.loc['Nature507','neighboring_texts'].index('GM study retracted')\n",
    "ida2=df_txt.loc['Nature507','neighboring_texts'].index('Bowing to scientists nearuniversal scorn,Food and Chemical Toxicology has retracted a controversial paper(G.-E.Séralini et al. FoodChem.Toxicol.50, 4221-4231; 2012) thatclaimed that Monsanto\\'s genetically modified(GM)maize (corn) causes serious disease in rats.The authorshad earlier refusedtowithdrawit.The paper showed\"no evidence of fraud or intentional misrepresentation of the data\", said a 28 November statement frompublishers Elsevier, but the small number and type of animals used in the study meanthat\"no definitive conclusions can be reached\" See go.nature.com/fk2auz for more.')\n",
    "idb1=df_txt.loc['Nature507','neighboring_texts'].index('Dance retraction')\n",
    "idb2=df_txt.loc['Nature507','neighboring_texts'].index('An eight-year-old Nature paper that reported a strong correlation between the symmetry of Jamaican dancers and their dancing ability was retracted on 27November (W.M.Brownetal.Nature http://doi.org/p9m; 2013).No reason is given in the retraction notice, but in April co-author Robert Trivers, an evolutionary biologist at Rutgers University inNewBrunswick,New Jersey, publicly released a university investigation report alleging that then-postdoc and co-author William Brown had faked data for the paper (see Nature 497,170-171;2013). Brown disputed the findings. Trivers has sought since 2008 to retract the paper, which implied that dancing ability might have evolved under sexual selection in humans.')\n",
    "\n",
    "idc1=df_txt.loc['Nature454','neighboring_texts'].index(\"Study retracted\")\n",
    "idc2=df_txt.loc['Nature454','neighboring_texts'].index(\"A landmark paper proposing a link between an influenza vaccine and narcolepsy was retracted on 31July.The study, publishedlast year (A.K.Dela Herran-Arita et al. Sci.Transl.Med.5,216ra176; 2013),reported that some people with narcolepsy had immune cells that target a wakefulness-maintaining neurotransmitter.The cells also recognize some components of flu vaccines, it said, and the results explainedwhy some children in Europe developed narcolepsy after receiving a vaccine forH1N1 swine flu. Butthe teamdiscovered that it could not reproduce its own findings,and so retracted the paper.See go.nature.com/ hbrrvi for more.\")\n",
    "ide=df_txt.loc['Nature454','neighboring_texts'].index('types of mature cells. In 2011,he stunned the world by mimicking an early stage in the development of the eye in vitro using embryonic stem cells.But over the past six months he became caught up in the controversy surroundingtwoNature papers that claimed embryonic stem cells could be created through a method called stimulus-triggered acquisition of pluripotency (STAP). The papers were retracted on 2 July after evidence of misconduct was found.Sasai, a co-author, was cleared of directinvolvementbutwas criticized for poor oversight of research.\"The world scientific community has lost an irreplaceable scientist\" said RIKEN president Ryoji Noyori. See go.nature.com/ etrboi for more.')\n",
    "\n",
    "texts_nature454 = df_txt.loc['Nature454', 'neighboring_texts']\n",
    "texts_nature507 = df_txt.loc['Nature507', 'neighboring_texts']\n",
    "\n",
    "df_txt.loc['Nature507b',:]=df_txt.loc['Nature507',:]\n",
    "df_txt.loc['Nature454b',:]=df_txt.loc['Nature454',:]\n",
    "\n",
    "df_txt[\"text\"]=df_txt['neighboring_texts'].str.join(\" \")\n",
    "\n",
    "df_txt.loc['Nature507b','text']='. '.join([texts_nature507[i] for i in [ida1, ida2]])\n",
    "df_txt.loc['Nature507','text']='. '.join([texts_nature507[i] for i in [idb1, idb2]])\n",
    "\n",
    "df_txt.loc['Nature454b','text']='. '.join([texts_nature454[i] for i in [ide]])\n",
    "df_txt.loc['Nature454','text']='. '.join([texts_nature454[i] for i in [idc1, idc2]])\n",
    "\n",
    "df_txt.loc[['Nature507','Nature507b','Nature454','Nature454b'],\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "ee001eac-f1df-4196-8df0-47baba3f16a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_txt[['path', 'folder', 'journal','labels', 'retraction_counts','text']].to_json(\"2025-06-06 PDF import filtered.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3c1f0553-d070-455b-809c-9d9441df52c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is not applied later -- It creates alternative text columns from the PDF import\n",
    "\n",
    "#from MyLib import labelfilter\n",
    "\n",
    "# Apply the functions to create new columns\n",
    "\n",
    "#df['filtered_texts'] = df.apply(lambda row: labelfilter.filter_texts(row['texts'], row['retraction_counts']), axis=1)\n",
    "\n",
    "#df['neighboring_texts'] = df.apply(lambda row: labelfilter.get_neighboring_texts(row['texts'], row['retraction_counts']), axis=1)\n",
    "#df['texts_until_section_header'] = df.apply(lambda row: labelfilter.get_texts_until_section_header(row['texts'], row['labels'], row['retraction_counts']), axis=1)\n",
    "#df[['texts', 'filtered_texts','neighboring_texts','texts_until_section_header']].apply(lambda col: col.apply(len).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8e0e1f-30b1-4b9b-9f9b-ba6b7828de11",
   "metadata": {},
   "source": [
    "# Create the flowchart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "adf858e5-28aa-485f-9295-0febf2ed8c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step_1: 1. eliminated because no pdf</th>\n",
       "      <th>step_2: 2. eliminated because corrupt file or no keyword</th>\n",
       "      <th>step_3: 3. eliminated because editorial retraction</th>\n",
       "      <th>step_4: 4. eliminated because book reviews, etc.</th>\n",
       "      <th>step_5: 5. eliminated because scanned with other relevant doc, duplicate or other technical issue</th>\n",
       "      <th>step_6: 6. eliminated because context/meaning</th>\n",
       "      <th>step_7: 7. eliminated because before 1960</th>\n",
       "      <th>Total documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>eliminated_count</th>\n",
       "      <td>385</td>\n",
       "      <td>410</td>\n",
       "      <td>59</td>\n",
       "      <td>198</td>\n",
       "      <td>228</td>\n",
       "      <td>854</td>\n",
       "      <td>81</td>\n",
       "      <td>3231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>remaining_count</th>\n",
       "      <td>2846</td>\n",
       "      <td>2436</td>\n",
       "      <td>2377</td>\n",
       "      <td>2179</td>\n",
       "      <td>1951</td>\n",
       "      <td>1097</td>\n",
       "      <td>1016</td>\n",
       "      <td>3231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            step_1: 1. eliminated because no pdf  \\\n",
       "elimina...        385                              \n",
       "remaini...       2846                              \n",
       "\n",
       "            step_2: 2. eliminated because corrupt file or no keyword  \\\n",
       "elimina...        410                                                  \n",
       "remaini...       2436                                                  \n",
       "\n",
       "            step_3: 3. eliminated because editorial retraction  \\\n",
       "elimina...         59                                            \n",
       "remaini...       2377                                            \n",
       "\n",
       "            step_4: 4. eliminated because book reviews, etc.  \\\n",
       "elimina...        198                                          \n",
       "remaini...       2179                                          \n",
       "\n",
       "            step_5: 5. eliminated because scanned with other relevant doc, duplicate or other technical issue  \\\n",
       "elimina...        228                                                                                           \n",
       "remaini...       1951                                                                                           \n",
       "\n",
       "            step_6: 6. eliminated because context/meaning  \\\n",
       "elimina...        854                                       \n",
       "remaini...       1097                                       \n",
       "\n",
       "            step_7: 7. eliminated because before 1960  Total documents  \n",
       "elimina...         81                                       3231        \n",
       "remaini...       1016                                       3231        "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530f26e2-853f-4db5-8d10-a212dbd1c3ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "1329598d-65e9-4040-8bd4-e612116c1c2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Step 1: No PDF available': eliminated_count     385\n",
       " remaining_count     2846\n",
       " Name: step_1: 1. eliminated because no pdf, dtype: int64,\n",
       " 'Step 2: Corrupt file or missing keyword': eliminated_count     410\n",
       " remaining_count     2436\n",
       " Name: step_2: 2. eliminated because corrupt file or no keyword, dtype: int64,\n",
       " 'Step 3: Editorial retraction': eliminated_count      59\n",
       " remaining_count     2377\n",
       " Name: step_3: 3. eliminated because editorial retraction, dtype: int64,\n",
       " 'Step 4: Excluded as book reviews or similar': eliminated_count     198\n",
       " remaining_count     2179\n",
       " Name: step_4: 4. eliminated because book reviews, etc., dtype: int64,\n",
       " 'Step 5: False article on page or duplicate': eliminated_count     228\n",
       " remaining_count     1951\n",
       " Name: step_5: 5. eliminated because scanned with other relevant doc, duplicate or other technical issue, dtype: int64,\n",
       " 'Step 6: Excluded due to irrelevant context': eliminated_count     854\n",
       " remaining_count     1097\n",
       " Name: step_6: 6. eliminated because context/meaning, dtype: int64,\n",
       " 'Step 7: Published before 1960': eliminated_count      81\n",
       " remaining_count     1016\n",
       " Name: step_7: 7. eliminated because before 1960, dtype: int64,\n",
       " 'Total documents': eliminated_count    3231\n",
       " remaining_count     3231\n",
       " Name: Total documents, dtype: int64}"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# New keys for the dictionary\n",
    "new_keys = {\n",
    "    'step_1: 1. eliminated because no pdf': 'Step 1: No PDF available',\n",
    "    'step_2: 2. eliminated because corrupt file or no keyword': 'Step 2: Corrupt file or missing keyword',\n",
    "    'step_3: 3. eliminated because editorial retraction': 'Step 3: Editorial retraction',\n",
    "    'step_4: 4. eliminated because book reviews, etc.': 'Step 4: Excluded as book reviews or similar',\n",
    "    'step_5: 5. eliminated because scanned with other relevant doc, duplicate or other technical issue': 'Step 5: False article on page or duplicate',\n",
    "    'step_6: 6. eliminated because context/meaning': 'Step 6: Excluded due to irrelevant context',\n",
    "    'step_7: 7. eliminated because before 1960': 'Step 7: Published before 1960',\n",
    "    'Total documents': 'Total documents'\n",
    "}\n",
    "\n",
    "# Create a new dictionary with renamed keys\n",
    "renamed_result = {new_keys[key]: value for key, value in result.items()}\n",
    "\n",
    "renamed_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "2f64ff4e-1878-4d05-b934-2d0b48e21e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "\n",
    "def create_flowchart(result):\n",
    "    # Create a new directed graph\n",
    "    flowchart = Digraph()\n",
    "    #flowchart.attr(rankdir='LR') \n",
    "    flowchart.attr(rankdir='LR', nodesep='0.1', ranksep='0.5',size='22,5')  # Adjusted spacing for a more compact layout\n",
    "\n",
    "    # Extract total documents and final remaining documents\n",
    "    total_docs = result['Total documents']['remaining_count']\n",
    "    final_remaining = result['Step 7: Published before 1960']['remaining_count']\n",
    "\n",
    "    # Add the total documents node\n",
    "    flowchart.node('A', f'Total Documents: \\n{total_docs}', shape='ellipse', style='filled', fillcolor='lightblue', fontsize='12', fontname=\"Helvetica\")\n",
    "\n",
    "    # Add nodes for each step\n",
    "    prev_node = 'A'\n",
    "    for i, (step, values) in enumerate(result.items()):\n",
    "        if step == 'Total documents':  # Skip the total documents key\n",
    "            continue\n",
    "        eliminated = values['eliminated_count']\n",
    "        remaining = values['remaining_count']\n",
    "        current_node = f'Step{i+1}'\n",
    "        step_description = step.split(\": \")[1]  # Extract the step description\n",
    "\n",
    "        flowchart.node(\n",
    "            current_node,\n",
    "            f'{step_description}\\nEliminated: {eliminated} \\n Remaining: {remaining}',\n",
    "            shape='box',\n",
    "            style='rounded,filled',\n",
    "           # fillcolor='lightgrey',\n",
    "            fontsize='12',  # Smaller font size for clarity\n",
    "            fontname=\"Helvetica\")\n",
    "        \n",
    "        flowchart.edge(prev_node, current_node)\n",
    "        prev_node = current_node\n",
    "\n",
    "    # Add the final remaining documents node\n",
    "        flowchart.node('Final', f'Final Remaining \\n Documents: \\n{final_remaining}', shape='ellipse', style='filled', fillcolor='lightgreen', \n",
    "                   fontsize='12', fontname='Helvetica-Bold')\n",
    "        \n",
    "    flowchart.edge(prev_node, 'Final')\n",
    "\n",
    "    # Render the flowchart to a file and display it\n",
    "    flowchart.render('flowchart3', format='pdf', cleanup=True)\n",
    "    flowchart.view()\n",
    "\n",
    "\n",
    "\n",
    "# Call the function to create the flowchart\n",
    "create_flowchart(renamed_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "6954c099-d768-43d7-ba6b-b9d273b76d98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Step 1: No PDF available</th>\n",
       "      <th>Step 2: Corrupt file or missing keyword</th>\n",
       "      <th>Step 3: Editorial retraction</th>\n",
       "      <th>Step 4: Excluded as book reviews or similar</th>\n",
       "      <th>Step 5: False article on page or duplicate</th>\n",
       "      <th>Step 6: Excluded due to irrelevant context</th>\n",
       "      <th>Step 7: Published before 1960</th>\n",
       "      <th>Total documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>eliminated_count</th>\n",
       "      <td>385</td>\n",
       "      <td>410</td>\n",
       "      <td>59</td>\n",
       "      <td>198</td>\n",
       "      <td>226</td>\n",
       "      <td>854</td>\n",
       "      <td>81</td>\n",
       "      <td>3231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>remaining_count</th>\n",
       "      <td>2846</td>\n",
       "      <td>2436</td>\n",
       "      <td>2377</td>\n",
       "      <td>2179</td>\n",
       "      <td>1953</td>\n",
       "      <td>1099</td>\n",
       "      <td>1018</td>\n",
       "      <td>3231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Step 1: No PDF available  Step 2: Corrupt file or missing keyword  \\\n",
       "elimina...        385                       410                                 \n",
       "remaini...       2846                      2436                                 \n",
       "\n",
       "            Step 3: Editorial retraction  \\\n",
       "elimina...         59                      \n",
       "remaini...       2377                      \n",
       "\n",
       "            Step 4: Excluded as book reviews or similar  \\\n",
       "elimina...        198                                     \n",
       "remaini...       2179                                     \n",
       "\n",
       "            Step 5: False article on page or duplicate  \\\n",
       "elimina...        226                                    \n",
       "remaini...       1953                                    \n",
       "\n",
       "            Step 6: Excluded due to irrelevant context  \\\n",
       "elimina...        854                                    \n",
       "remaini...       1099                                    \n",
       "\n",
       "            Step 7: Published before 1960  Total documents  \n",
       "elimina...         81                           3231        \n",
       "remaini...       1018                           3231        "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(renamed_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

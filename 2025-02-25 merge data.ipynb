{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed0875e6-ae2c-45be-9a61-ad295f90c4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm # progress apply :)\n",
    "tqdm.pandas()\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "def d(l):\n",
    "    pd.set_option('display.max_colwidth', l)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b1db5f4-af6f-404d-a1a0-6145a2dfa1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just to check if new articles are included\n",
    "new_articles=pd.read_excel(\"2025-04-26 Manual Annotation results_Inclusion.xlsx\")[\"ID\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc66d8f7-ef53-4e35-834f-490b63b4fcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_country_fields=pd.read_json(\"2025-06-07 Country_fields results.json\")\n",
    "df_dict=pd.read_json('2025-06-07 data with dict_approach.json')\n",
    "df_GPT4=pd.read_json(\"2025-06-08 full data with 6x GPT41.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ebcc2ad7-4f72-413d-a8de-f1d1ed76f987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94    Mistake\n",
       "Name: category, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_GPT4[df_GPT4.name==\"Nature1223\"].category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0adfa65-af17-4243-b3a5-b26c59daf5f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a1c01d1-7102-4256-8da3-367414a0d262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT files 17 17\n",
      "dict approach 17 17\n",
      "country fields 17 17\n"
     ]
    }
   ],
   "source": [
    "# Check if also the new articles are in the processed collections\n",
    "print(\"GPT files\",df_GPT4[df_GPT4.name.isin(new_articles)].shape[0],len(new_articles))\n",
    "print(\"dict approach\",df_dict[df_dict.name.isin(new_articles)].shape[0],len(new_articles))\n",
    "print(\"country fields\",df_country_fields[df_country_fields.name.isin(new_articles)].shape[0],len(new_articles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e468f9e0-5d12-4dfe-acc6-de05e51f709b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3231, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Doi</th>\n",
       "      <th>journal</th>\n",
       "      <th>Title</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Type</th>\n",
       "      <th>Type Recoded</th>\n",
       "      <th>confirmed_2024</th>\n",
       "      <th>9. retained for analysis (revised)</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Nature1</th>\n",
       "      <td>Nature1</td>\n",
       "      <td>10.1038/d41586-023-01969-z</td>\n",
       "      <td>Nature</td>\n",
       "      <td>Prized dinosaur fossil returned to Brazil afte...</td>\n",
       "      <td>2023-06-22</td>\n",
       "      <td>2023</td>\n",
       "      <td>News</td>\n",
       "      <td>Journalism</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Nature1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nature10</th>\n",
       "      <td>Nature10</td>\n",
       "      <td>10.1038/d41586-023-01416-z</td>\n",
       "      <td>Nature</td>\n",
       "      <td>Fish on dry land hint at why we blink</td>\n",
       "      <td>2023-04-27</td>\n",
       "      <td>2023</td>\n",
       "      <td>Research Highlights</td>\n",
       "      <td>Other</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Nature10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nature100</th>\n",
       "      <td>Nature100</td>\n",
       "      <td>10.1038/d41586-021-01457-2</td>\n",
       "      <td>Nature</td>\n",
       "      <td>Cells or drugs? The race to regenerate the heart</td>\n",
       "      <td>2021-06-09</td>\n",
       "      <td>2021</td>\n",
       "      <td>Comments &amp; Opinion</td>\n",
       "      <td>Journalism</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Nature100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nature1000</th>\n",
       "      <td>Nature1000</td>\n",
       "      <td>10.1038/118855a0</td>\n",
       "      <td>Nature</td>\n",
       "      <td>Research Items</td>\n",
       "      <td>1926-12-11</td>\n",
       "      <td>1926</td>\n",
       "      <td>News</td>\n",
       "      <td>Contribution</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Nature1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nature1001</th>\n",
       "      <td>Nature1001</td>\n",
       "      <td>10.1038/news050926-10</td>\n",
       "      <td>Nature</td>\n",
       "      <td>Water walkers surf on the edge</td>\n",
       "      <td>2005-09-28</td>\n",
       "      <td>2005</td>\n",
       "      <td>News</td>\n",
       "      <td>Contribution</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Nature1001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ID                         Doi journal  \\\n",
       "ID                                                           \n",
       "Nature1        Nature1  10.1038/d41586-023-01969-z  Nature   \n",
       "Nature10      Nature10  10.1038/d41586-023-01416-z  Nature   \n",
       "Nature100    Nature100  10.1038/d41586-021-01457-2  Nature   \n",
       "Nature1000  Nature1000            10.1038/118855a0  Nature   \n",
       "Nature1001  Nature1001       10.1038/news050926-10  Nature   \n",
       "\n",
       "                                                        Title       Date  \\\n",
       "ID                                                                         \n",
       "Nature1     Prized dinosaur fossil returned to Brazil afte... 2023-06-22   \n",
       "Nature10                Fish on dry land hint at why we blink 2023-04-27   \n",
       "Nature100    Cells or drugs? The race to regenerate the heart 2021-06-09   \n",
       "Nature1000                                     Research Items 1926-12-11   \n",
       "Nature1001                     Water walkers surf on the edge 2005-09-28   \n",
       "\n",
       "            Year                 Type  Type Recoded  confirmed_2024  \\\n",
       "ID                                                                    \n",
       "Nature1     2023                 News    Journalism            True   \n",
       "Nature10    2023  Research Highlights         Other           False   \n",
       "Nature100   2021   Comments & Opinion    Journalism            True   \n",
       "Nature1000  1926                 News  Contribution           False   \n",
       "Nature1001  2005                 News  Contribution           False   \n",
       "\n",
       "            9. retained for analysis (revised)        name  \n",
       "ID                                                          \n",
       "Nature1                                   True     Nature1  \n",
       "Nature10                                 False    Nature10  \n",
       "Nature100                                 True   Nature100  \n",
       "Nature1000                               False  Nature1000  \n",
       "Nature1001                               False  Nature1001  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta_data=pd.read_excel(\"2025-06-07 all meta data.xlsx\")[['ID', 'Doi', 'journal', 'Title', 'Date', 'Year', 'Type',\n",
    "       'Type Recoded', 'confirmed_2024', '9. retained for analysis (revised)']]\n",
    "\n",
    "df_meta_data[\"name\"]=df_meta_data.ID\n",
    "df_meta_data.index=df_meta_data.ID\n",
    "#df_meta_data.rename(columns={\"ID\": \"name\",\"Doi_x\": \"Doi\"},inplace=True)\n",
    "\n",
    "print(df_meta_data.shape)\n",
    "df_meta_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e59b972-113b-41b2-ba33-536d1bd07d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1018, 35)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start with the first DataFrame\n",
    "\n",
    "df_merged = df_meta_data\n",
    "\n",
    "# Iteratively merge the remaining DataFrames on the \"name\" column\n",
    "for df in [df_country_fields ,df_dict,df_GPT4]:\n",
    "    df_merged = pd.merge(df_merged, df, on=\"name\", how=\"outer\",suffixes=(None, '_y'))\n",
    "# df_merged[df_merged[\"Year\"].isna()][df_old.columns].to_excel(\"2025_02_04 missing_date_DOI_Type_recoded.xlsx\")\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f013bf36-51d7-4146-9b29-8645fa125e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_merged.rename(columns={\"text_x\":\"text\"},inplace=True)\n",
    "df=df_merged[df_merged[\"9. retained for analysis (revised)\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a7f7139b-2c97-4508-a9a3-338e49a35c1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1016, 74)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bfc1133a-2d5b-4fa8-ab82-b9bd9e72f565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "Misconduct    626\n",
       "Mistake       230\n",
       "None          160\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"category\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819ebd83-8df6-4237-a76d-1d04e0e769cd",
   "metadata": {},
   "source": [
    "# Add manual Annotation (classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ca70ac54-5cb2-4df8-9b9f-e7a9731e9a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.loc[(df[\"category\"]!=\"Misconduct\"),[\"name\",\"retraction_text\",\"text\",'category',\"explanation\"]].to_excel(\"2025-06-06 Mistake_none Sample for manual annotation.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "38841f63-047f-4dfb-84d5-a6a28630555d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts\n",
      "1    191\n",
      "2     18\n",
      "3      3\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List of file paths and corresponding dataset numbers\n",
    "files = [\n",
    "    (\"2025-02-24 Sample for manual annotation_filled.xlsx\", 1),\n",
    "    (\"2025-03-07 Sample for manual annotation filled.xlsx\", 2),\n",
    "    (\"2025-03-07 2nd Sample for manual annotation filled.xlsx\", 3),\n",
    "    (\"2025-06-06 none_mistake sample ANNOTATED.xlsx\", 4),\n",
    "    (\"2025-06-08 Sample Auste Annotated 2024-03-19.xlsx\", 5),\n",
    "\n",
    "\n",
    "]\n",
    "\n",
    "dfs = []\n",
    "for filepath, num in files:\n",
    "    dfa = (\n",
    "        pd.read_excel(filepath)[[\"name\", \"Max code\"]]\n",
    "        .dropna(subset=[\"Max code\"])\n",
    "        .set_index(\"name\")\n",
    "    )\n",
    "    dfa[\"Max code\"] = dfa[\"Max code\"].str.lower()\n",
    "    dfa.rename(columns={\"Max code\": f\"Max code_{num}\"}, inplace=True)\n",
    "    \n",
    "    # Optional: remove duplicated index entries within each dataframe, keeping last\n",
    "    dfa = dfa[~dfa.index.duplicated(keep='last')]\n",
    "    \n",
    "    dfs.append(dfa)\n",
    "\n",
    "# Concatenate all dataframes along columns, aligning on index 'name'\n",
    "df_annotated = pd.concat(dfs, axis=1)\n",
    "\n",
    "# Identify rows where values differ across datasets\n",
    "df_annotated[\"all_equal\"] = df_annotated.nunique(axis=1) == 1\n",
    "df_annotated[\"counts\"] = df_annotated.drop(columns=[\"all_equal\"]).count(axis=1)\n",
    "\n",
    "# Filter rows with differences\n",
    "df_differences = df_annotated[~df_annotated[\"all_equal\"]].drop(columns=[\"all_equal\", \"counts\"])\n",
    "\n",
    "# Create a new column \"Max code\" that takes the first non-NaN value from the Max code columns\n",
    "max_code_columns = [col for col in df_annotated.columns if col.startswith('Max code_')]\n",
    "df_annotated['Max code'] = df_annotated[max_code_columns].bfill(axis=1).iloc[:, 0]\n",
    "\n",
    "# Example: count of counts values\n",
    "print(df_annotated.counts.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c10be741-bacd-45fc-bb10-b0ad3312776d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "('Max code', 'category', 'dict-topic')",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\PyMax\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: ('Max code', 'category', 'dict-topic')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdf_annotated\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mMax code\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcategory\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdict-topic\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m.to_excel(\u001b[33m\"\u001b[39m\u001b[33m2025-06-12\u001b[39m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m Annotation results.xlsx\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\PyMax\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\PyMax\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: ('Max code', 'category', 'dict-topic')"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a4e112-1364-445b-9f5c-f89eea27dd90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "74446eb6-3479-4aa4-8d4f-6ed04a1f919b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1016, 82)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#df_final.dropna(subset=\"category\")\n",
    "\n",
    "df_final = df.merge(df_annotated, left_on=\"name\",right_on=\"name\", how=\"left\")\n",
    "df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd212069-6215-4857-8f35-2550234d64ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "6793d63e-741e-46ec-ac0f-6a541bd3cb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all columns with '_y' in their names and remove duplicate columns\n",
    "df_final = df_final.loc[:, ~df_final.columns.duplicated()]  # Remove duplicate columns\n",
    "df_final = df_final.drop(columns=[col for col in df.columns if '_y' in col])  # Drop columns with '_y'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "5611891c-66ad-4156-af79-532d85ca9352",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_final=df_final.dropna(subset=\"Year\")\n",
    "df_final.sort_values(\"name\").to_json(\"2025-06-06 Merged_Data.json\", date_format='iso')\n",
    "df_final.sort_values(\"name\").to_excel(\"2025-06-06 Merged_Data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "df88b557-e20f-40d7-bcfd-7badd2247ad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'Doi', 'journal', 'Title', 'Date', 'Year', 'Type', 'Type Recoded',\n",
       "       'confirmed_2024', '9. retained for analysis (revised)', 'name',\n",
       "       'contains_country', 'country_plus_city', 'Most Common country',\n",
       "       'Most Common country_no_city', 'all_jobs', 'fields',\n",
       "       'most_common_fields', 'path', 'folder', 'labels', 'retraction_counts',\n",
       "       'text', 'sentiment', 'keywords_likely', 'keywords_only',\n",
       "       'keywords_filtered', 'Lemmata', 'NoStopwords', 'Nouns_Verbs',\n",
       "       'ner_orga', 'ner_person', 'misconduct', 'mistake', 'retract',\n",
       "       'n_misconduct', 'n_mistake', 'n_retract', 'dict_topic', 'category_1',\n",
       "       'explanation_1', 'original_index', 'name_2', 'category_2',\n",
       "       'explanation_2', 'country_1', 'field_1', 'name_3', 'category_3',\n",
       "       'explanation_3', 'country_3', 'field_3', 'name_4', 'category_4',\n",
       "       'explanation_4', 'country_4', 'field_4', 'name_5', 'category_5',\n",
       "       'explanation_5', 'country_5', 'field_5', 'name_6', 'category_6',\n",
       "       'explanation_6', 'category', 'difference_count', 'Max code_1',\n",
       "       'Max code_2', 'Max code_3', 'Max code_4', 'Max code_5', 'all_equal',\n",
       "       'counts', 'Max code'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "6ee80cda-3c30-4a77-9ede-144b5887adf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Doi</th>\n",
       "      <th>journal</th>\n",
       "      <th>Title</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Type</th>\n",
       "      <th>Type Recoded</th>\n",
       "      <th>confirmed_2024</th>\n",
       "      <th>9. retained for analysis (revised)</th>\n",
       "      <th>...</th>\n",
       "      <th>category</th>\n",
       "      <th>difference_count</th>\n",
       "      <th>Max code_1</th>\n",
       "      <th>Max code_2</th>\n",
       "      <th>Max code_3</th>\n",
       "      <th>Max code_4</th>\n",
       "      <th>Max code_5</th>\n",
       "      <th>all_equal</th>\n",
       "      <th>counts</th>\n",
       "      <th>Max code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ID, Doi, journal, Title, Date, Year, Type, Type Recoded, confirmed_2024, 9. retained for analysis (revised), name, contains_country, country_plus_city, Most Common country, Most Common country_no_city, all_jobs, fields, most_common_fields, path, folder, labels, retraction_counts, text, sentiment, keywords_likely, keywords_only, keywords_filtered, Lemmata, NoStopwords, Nouns_Verbs, ner_orga, ner_person, misconduct, mistake, retract, n_misconduct, n_mistake, n_retract, dict_topic, category_1, explanation_1, original_index, name_2, category_2, explanation_2, country_1, field_1, name_3, category_3, explanation_3, country_3, field_3, name_4, category_4, explanation_4, country_4, field_4, name_5, category_5, explanation_5, country_5, field_5, name_6, category_6, explanation_6, category, difference_count, Max code_1, Max code_2, Max code_3, Max code_4, Max code_5, all_equal, counts, Max code]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 75 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final[df_final.text.isna()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
